{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba5594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공신경망에서 심층을 여러 개 둔 것이 심층 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43551d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "(x_train,y_train),(x_target,y_target) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train.shape # 3차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea3c3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사이킷런 이용하여 스케일링 하기\n",
    "# - 2차원 배열만 허용\n",
    "\n",
    "# 3차원 --> 2차원으로 차수 변환\n",
    "x_train_2d = x_train.reshape(-1, 28*28)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x_train_scaled = ss.fit_transform(x_train_2d)\n",
    "x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ea9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8:2 로 분류\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_sc, x_target_sc, y_train_sc, y_target_sc = train_test_split(x_train_scaled, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e595d37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 784), (48000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sc.shape, y_train_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6e0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 분류의 출력층 -> 시그모이드 함수\n",
    "# 다중 분류의 출력층 -> 소프트맥스 함수\n",
    "\n",
    "# 은닉층 만들기\n",
    "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(28*28,)) # 튜플 형태로 주기\n",
    "# 100개의 결과(뉴런) 생성\n",
    "# 출력할 때는 다중 분류이므로 소프트맥스 함수를 이용하나,\n",
    "# 은닉층을 만들 땐, 데이터가 중첩되지 않게 곡선을 사용해야 하므로 시그모이드 함수 사용한 것\n",
    "\n",
    "# 출력층 만들기\n",
    "dense2 = keras.layers.Dense(10, activation='softmax')\n",
    "# 마지막에 출력을 해주는 층이므로 input_shape로 변환해 줄 필요 X\n",
    "\n",
    "model = keras.Sequential([dense1, dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2227e0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# 은닉층 100개 생성, 마지막 출력층 10개로 구성, 출력층에서 소프트맥스함수 이용하여 분류를 한 것이 정답(뉴런)\n",
    "# - 은닉층은 784개의 데이터가 100개로 압축된 것\n",
    "# - Param : 784 * 100 + 100(절편) --> 784개의 데이터를 각각 100번씩 훈련하고 훈련할 때마다 하나의 절편값이 함께 더해져 나온 값\n",
    "# - Param : 100 * 10 + 10(절편)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ffc1a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항상 위처럼 구성하는 것은 아님\n",
    "# 다르게 구성해 보기 (층 한꺼번에 구성)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation='sigmoid', input_shape=(28*28,)),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "], name = '패션 MNIST 모델' # 모델명 주기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90d0eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"패션 MNIST 모델\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7649658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또 다른 구성 방법 (층을 하나씩 생성)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(28*28,)),)\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 둘 중 편한 방법으로 사용하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31112dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92279343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.4669 - accuracy: 0.8354\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3540 - accuracy: 0.8730\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3195 - accuracy: 0.8856\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2961 - accuracy: 0.8935\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2757 - accuracy: 0.9004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f692ccad00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc, y_train_sc, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c353cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 층 여러 개 주기\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(500, activation='sigmoid', input_shape=(28*28,)),) # 784 * 500 + 500\n",
    "# model.add(keras.layers.Dense(400, activation='sigmoid') # 500 * 400 + 400\n",
    "# model.add(keras.layers.Dense(300, activation='sigmoid') # 400 * 300 + 300\n",
    "# model.add(keras.layers.Dense(200, activation='sigmoid') # 300 * 400 + 400\n",
    "# model.add(keras.layers.Dense(100, activation='sigmoid') # 200 * 100 + 100\n",
    "\n",
    "# 그런데 input_shape()값을 모두 동일하게 (28*28, ) 적용하거나, 다른 값을 지정해 주거나,\n",
    "# 첫째값 제외 나머지 input_shape()값은 생략하는 경우 모두 동일한 결과값이 나옴...왜?\n",
    "\n",
    "# --> 첫번째 입력층을 지정해 준다 하더라도 최초의 입력층값을 시작으로 적용하고\n",
    "#     다음층부터는 input_shape값을 무시하기 때문\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfcf8517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 500)               392500    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 397,510\n",
      "Trainable params: 397,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af54bbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 0.2211 - accuracy: 0.9204\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.1987 - accuracy: 0.9282\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.1800 - accuracy: 0.9354\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.1643 - accuracy: 0.9404\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.1488 - accuracy: 0.9473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f6939486d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc, y_train_sc, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4fcc0f",
   "metadata": {},
   "source": [
    "#### 초기 인공지능의 신경망의 은닉층에 많이 사용된 활성화 함수는 시그모이드\n",
    "#### 오른쪽이나 왼쪽으로 갈수록 0과 1에 가까운 수를 반환하기 때문에 \n",
    "#### 함수 적용 효과가 떨어지고 결과값도 큰 차이가 없음\n",
    "\n",
    "#### 따라서 가중치를 즉각적으로 반영하기 위해...relu 함수 사용\n",
    "##### - relu : 이미지 처리에 좋은 성능을 낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a5a9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten 층은 데이터를 1차원으로 펼쳐 입력 시켜주는 층\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28*28,))) # flatten은 참여를 해주는 것은 아니기 때문에 파라미터 값이 0\n",
    "model.add(keras.layers.Dense(500, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "388cabbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 18s 11ms/step - loss: 0.5482 - accuracy: 0.8285\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.4307 - accuracy: 0.8690\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.3894 - accuracy: 0.8844\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.3779 - accuracy: 0.8938\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.3533 - accuracy: 0.8998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f695480b80>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "# 하나의 평가방법만 쓰는 것처럼 알 수 있으니, 여러 방법을 쓸 때에는 리스트 형식으로 넣어주어야 정확도가 높아짐\n",
    "model.fit(x_train_sc, y_train_sc, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b467e804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 784), (12000,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_target_sc.shape, y_target_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2ca0728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5083 - accuracy: 0.8771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5083163380622864, 0.8770833611488342]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_target_sc, y_target_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5f5957",
   "metadata": {},
   "source": [
    "### 인공신경망은 기본적으로 확률적 경사 하강법이므로 기본만 사용하면 머신러닝과 비슷함\n",
    "#### SGDClassifier (로지스틱 회귀) : sklearn에서 제공\n",
    "\n",
    "#### 인공신경망 + 은닉층 + 은닉층 + ... + 은닉층 n --> keras에서 제공\n",
    "#### 은닉층의 결과를 뉴런, 즉 출력층이라고 하며\n",
    "#### 은닉층이 마지막 출력을 뜻하면 그것이 곧 출력층 (활성화 함수 : softmax)\n",
    "#### 그 외 은닉층 : sigmoid (선형 회귀의 식을 곡선으로 만들어 다음 결과가 중첩되지 않도록 하기 위함)\n",
    "\n",
    "#### - sigmoid 단점 : 값이 증가할수록 변화가 거의 없으므로 어떤 상황을 즉각적으로 반영할 수 없음 --> relu 함수로 개선\n",
    "#### - relu :  0보다 클 때는 실제값을 반영하고, 0보다 작을 때는 전부 0으로 처리\n",
    "    ** 은닉층을 사용한 경우가 사용하지 않은 경우 보다 약간 개선된 것을 확인할 수 있음 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a1f85f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile() --> 경사하강법...optimizers의 디폴트값인 RMSprop 알고리즘 사용 --> 확률적 경사 하강법 (하나씩 꺼내는 것)\n",
    "# optimizers.SGD() -->  (나머지는) 미니배치 경사하강법\n",
    "# 특히 신경망에 하이퍼 파라미터값이 많음 (은닉층 또한 하이퍼 파라미터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db0c2de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 11s 6ms/step - loss: 0.3546 - accuracy: 0.9251\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.2970 - accuracy: 0.9308\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.3004 - accuracy: 0.9334\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.2637 - accuracy: 0.9378\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2615 - accuracy: 0.9393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f695744df0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = keras.optimizers.SGD(learning_rate=0.01) # Default : 0.001\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "# model 디자인은 바뀌지 않음\n",
    "# complie을 해 주면 모델의 성능을 다시 측정, 그러나 compile을 안하고 fit만 해주면 훈련 횟수가 누적돼버림\n",
    "model.fit(x_train_sc, y_train_sc, epochs=5)\n",
    "# dense값이 모두 동일한 상태에서 옵티마이저값만 바꿔주었는데도\n",
    "# 처음부터 90%가 넘는 확률이 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d899940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.5378 - accuracy: 0.8630\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.9617 - accuracy: 0.8900\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.8603 - accuracy: 0.8955\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4438 - accuracy: 0.9172\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.3851 - accuracy: 0.9219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f6957dfe50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = keras.optimizers.SGD(learning_rate=0.1) # Default : 0.001 --> 0.1\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc, y_train_sc, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e6cfe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.4605 - accuracy: 0.8395\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.3400 - accuracy: 0.8791\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.2928 - accuracy: 0.8939\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.2607 - accuracy: 0.9045\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.2373 - accuracy: 0.9147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f6d20cdd00>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD 클래스에는 momentum 함수도 존재함 (Default : 0)\n",
    "#      momentum : 내려오는 속도, like 산에서 달려 내려오기\n",
    "#      nesterov=True값을 주어야 momentum이 실행됨\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28*28,))) # compile 두 번 이상하면 Error이므로 모델 다시 초기화\n",
    "model.add(keras.layers.Dense(500, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 매개변수 튜닝 전 sgd.get_config()로 기본 파라미터 디폴트값 확인하기\n",
    "\n",
    "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True) \n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc, y_train_sc, epochs=5)\n",
    "# 에포크가 많을 때의 성능을 보는 것임\n",
    "# 여기에서는 정확도가 현저히 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e96ac75",
   "metadata": {},
   "source": [
    "#### *'인공신경망 optimizer gif' 검색하여 영상으로 보다 쉽게 이해하기*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a405976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.5194 - accuracy: 0.8193\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.3750 - accuracy: 0.8665\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3366 - accuracy: 0.8799\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3123 - accuracy: 0.8895\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2924 - accuracy: 0.8955\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3449 - accuracy: 0.8785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3449268937110901, 0.8784999847412109]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning_rate값 기본값으로 줬을 때\n",
    "# 네스테로프 모멘텀 : 속도, 모멘텀 최적화 2번 반복하여 구현\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28*28,))) # compile 두 번 이상하면 Error이므로 모델 다시 초기화\n",
    "model.add(keras.layers.Dense(500, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = keras.optimizers.SGD() # learning_rate : 0.01    momentum : 0\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc, y_train_sc, epochs=5)\n",
    "model.evaluate(x_target_sc, y_target_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f60e0a",
   "metadata": {},
   "source": [
    "### 촘촘히 내려가는 게 아니라 듬성듬성 내려가는 것을 구현하는 알고리즘...\n",
    "### Adagrad & RMSProps(Optimizers의 Default)\n",
    "### - 모델이 최적점에 가까이 갈수록 학습율(learning_rate)을 낮출 수 있고,\n",
    "###   이렇게 하면 안정적으로 최적점에 도착할 가능성이 높음 --> 적응적 학습율\n",
    "### - 매개변수 튜닝을 안 해 주어도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64b03342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.6979 - accuracy: 0.7636\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4775 - accuracy: 0.8335\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4323 - accuracy: 0.8482\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4070 - accuracy: 0.8560\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.3900 - accuracy: 0.8628\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4138 - accuracy: 0.8544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41383904218673706, 0.8544166684150696]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28*28,))) # compile 두 번 이상하면 Error이므로 모델 다시 초기화\n",
    "model.add(keras.layers.Dense(500, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 매개변수 튜닝 전 adagrad.get_config()로 기본 파라미터 디폴트값 확인하기 (함수 마다 다름)\n",
    "\n",
    "adagrad = keras.optimizers.Adagrad() # learning_rate : 0.001    momentum : 0\n",
    "model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc, y_train_sc, epochs=5)\n",
    "model.evaluate(x_target_sc, y_target_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "418af5f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4953 - accuracy: 0.8323\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.3533 - accuracy: 0.8729\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.3203 - accuracy: 0.8851\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2940 - accuracy: 0.8950\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.2671 - accuracy: 0.9039\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3945 - accuracy: 0.8798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39452749490737915, 0.8798333406448364]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모멘텀 최적화와 RMSProps의 장점을 묶은 게...Adam\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28*28,))) # compile 두 번 이상하면 Error이므로 모델 다시 초기화\n",
    "model.add(keras.layers.Dense(500, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 매개변수 튜닝 전 adam.get_config()로 기본 파라미터 디폴트값 확인하기 (함수 마다 다름)\n",
    "\n",
    "adam = keras.optimizers.Adam() # learning_rate : 0.01    momentum : 0\n",
    "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc, y_train_sc, epochs=5)\n",
    "model.evaluate(x_target_sc, y_target_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd497a6",
   "metadata": {},
   "source": [
    "# 이론적으로는 optimizers 중 Adam의 성능이 가장 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560adca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저\n",
    "# - SGD : 기본 경사하강법의 옵티마이저\n",
    "#   - learning_mate : 0.01\n",
    "#   - momentum 값을 0 이상 주면 momentum(움직임) 최적화 수행\n",
    "#   - nesterov=True 설정 --> nesterov momentum 최적화 수행\n",
    "\n",
    "# - Adagrad\n",
    "#   - learning_mate : 0.001\n",
    "#   - 그라디언트를 제곱하고 누적하여 학습율로 나누어 제공\n",
    "#   - initial_accumulator_value : Default : 0.1\n",
    "\n",
    "# - RMSprops\n",
    "#   - learning_mate : 0.001\n",
    "#   - 그라디언트를 제곱하고 누적하여 학습율로 나누지만 최근의 그라디언트를 사용하기 위해 '지수 감소'를 사용\n",
    "#   - rho(감소비율) : Dafault : 0.9\n",
    "\n",
    "# - Adam\n",
    "#   - learning_mate : 0.01\n",
    "#   - momentum 을 최적화 하기 위해 그라디언트 지수를 감소시키는데,\n",
    "#     평균을 조절하기 위해 beta_1 매개변수 사용\n",
    "#     beta_1 : Default : 0.9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
